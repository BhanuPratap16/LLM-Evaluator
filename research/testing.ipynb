{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765bcc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'This request requires more credits, or fewer max_tokens. You requested up to 16384 tokens, but can only afford 4000. To increase, visit https://openrouter.ai/settings/credits and upgrade to a paid account', 'code': 402, 'metadata': {'provider_name': None}}, 'user_id': 'user_31UfszDQcIPcr8XmbzRWCxaMuxf'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    " \n",
    "\n",
    "with open(\"config.json\",'r') as f:\n",
    "    data=json.load(f)\n",
    "api_key=data['openrouter_api_key']\n",
    "questions=data['questions']\n",
    "response = requests.post(\n",
    "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "  headers={\"Authorization\":f\"Bearer {api_key}\"},\n",
    "  data=json.dumps({\n",
    "    \"model\": \"openai/gpt-4o\", # Optional\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": questions[0]\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    ")\n",
    "\n",
    "print(response.json())\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from google import genai\n",
    "with open(\"config.json\",'r') as f:\n",
    "    data=json.load(f)\n",
    "api_key=data['google_ai_api_key']\n",
    "questions=data['questions']\n",
    "style=data['coding-style']\n",
    "client=genai.Client(api_key=api_key)\n",
    "\n",
    "response=client.models.generate_content(\n",
    "    model='gemini-2.5-flash',contents=f\"{questions[0]} - only provide code and refer to {style} for proper coding style and nothing else also keep in mind to remove c ``` at starting and ``` in the end of the code and keep author name as Bhanu\"\n",
    ")\n",
    "\n",
    "with open(\"Shared/ldd.c\",'w') as f:\n",
    "    f.write(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20da18ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
      "models/gemini-1.5-pro-latest ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-preview-image-generation ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/embedding-001 ['embedContent']\n",
      "models/text-embedding-004 ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/aqa ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 ['predict']\n",
      "models/imagen-4.0-generate-preview-06-06 ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 ['predict']\n",
      "models/imagen-4.0-generate-001 ['predict']\n",
      "models/imagen-4.0-ultra-generate-001 ['predict']\n",
      "models/imagen-4.0-fast-generate-001 ['predict']\n",
      "models/veo-2.0-generate-001 ['predictLongRunning']\n",
      "models/veo-3.0-generate-preview ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-preview ['predictLongRunning']\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-live-2.5-flash-preview ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-live-preview ['bidiGenerateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "for m in client.models.list():\n",
    "    print(m.name, m.supported_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384b40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from google import genai\n",
    "import yaml \n",
    "with open(\"config.json\",'r') as f:\n",
    "    data=json.load(f)\n",
    "api_key=data['google_ai_api_key']\n",
    "questions=data['questions']\n",
    "\n",
    "with open(\"Shared/tidy_fixes.yaml\",'r') as f:\n",
    "    fixes=yaml.safe_load(f)\n",
    "    \n",
    "with open(\"Shared/ldd.c\",'r') as f:\n",
    "    fix_code=f.read()\n",
    "\n",
    "client=genai.Client(api_key=api_key)\n",
    "\n",
    "response=client.models.generate_content(\n",
    "    model='gemini-2.5-flash',contents=f\"Given <br> {fix_code} <br> ,these are the errors in it:{fixes}, fix the code and only provide code and nothing else also keep in mind to remove c ``` at starting and ``` in the end of the code and keep author name as Bhanu\"\n",
    ")\n",
    "\n",
    "with open(\"Shared/ldd.c\",'w') as f:\n",
    "    f.write(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f08a381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
